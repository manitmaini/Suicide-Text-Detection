{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFCedZK5tjKb"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "This notebook aims to apply the CNN model to perform text classification and detect suicidal text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsC8c2KgvVYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963c6f65-15c7-423e-9f5c-1bd86a7b27cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z25kuEC1uHDX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, f1_score, precision_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWH7zlQttGK4"
      },
      "source": [
        "# Specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6PuOIbSgTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120038a3-d254-425d-93ab-2f03fa91ca17"
      },
      "source": [
        "# Change to your own directory\n",
        "try: \n",
        "    os.chdir(\"/content/drive/MyDrive/Suicide Project\")\n",
        "    print(\"Directory changed\")\n",
        "except OSError:\n",
        "    print(\"Error: Can't change the Current Working Directory\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory changed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOKU3N86Zdd4"
      },
      "source": [
        "## Define constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqtxDrajt1V1"
      },
      "source": [
        "# Define constants\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-5\n",
        "SEED = 4222"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf1MoMxaZhQz"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T98zLXPUvjrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b5a8682b-e2e2-4edf-8955-5ab28bb99b69"
      },
      "source": [
        "# Load dataset\n",
        "suicide_detection_df = pd.read_csv('Data/suicide_detection_final_cleaned.csv', header=0)\n",
        "suicide_detection_df.drop(columns=['text'], axis=1, inplace=True)\n",
        "suicide_detection_df = suicide_detection_df.rename(columns={\"cleaned_text\": \"text\"})\n",
        "classes = {\"suicide\": 1, \"non-suicide\": 0}\n",
        "suicide_detection_df = suicide_detection_df.replace({\"class\": classes})\n",
        "suicide_detection_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class                                               text\n",
              "0      1  sex wife threaten suicide recently leave wife ...\n",
              "1      0  weird not affect compliment come know girl fee...\n",
              "2      0      finally hear bad year swear fuck god annoying\n",
              "3      1                            need help help cry hard\n",
              "4      1                       end tonight not anymore quit"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17afb1b3-676e-4f8b-a88f-e0e61ec82b0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sex wife threaten suicide recently leave wife ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>weird not affect compliment come know girl fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>finally hear bad year swear fuck god annoying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>need help help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17afb1b3-676e-4f8b-a88f-e0e61ec82b0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17afb1b3-676e-4f8b-a88f-e0e61ec82b0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17afb1b3-676e-4f8b-a88f-e0e61ec82b0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx9nsttJZkLX"
      },
      "source": [
        "## Train-Test-Val Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I85QRroxx6v-"
      },
      "source": [
        "# Split dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(suicide_detection_df['text'], suicide_detection_df['class'],\n",
        "                                                                    random_state=SEED,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=suicide_detection_df['class'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=SEED,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PLibDtXZuMg"
      },
      "source": [
        "## Max Length and Number of vocab words in Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tunrph0wZx4V",
        "outputId": "dc3ea852-ab42-41b8-a5d3-7a3635857e0b"
      },
      "source": [
        "max_length = max([len(s.split()) for s in train_text])\n",
        "max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4BTNhb2Z0E7"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1CeTgBRZ3HR"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzBoL6ARZ2Oa"
      },
      "source": [
        "def tokenize_and_encode(text, max_length=62):\n",
        "    \"\"\"Tokenize and encode sequences.\"\"\"\n",
        "\n",
        "    # sequence encode\n",
        "    encoded_docs = tokenizer.texts_to_sequences(text)\n",
        "    # pad sequences\n",
        "    padded_sequence = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "\n",
        "    return padded_sequence\n",
        "\n",
        "# Tokenize and encode sequences in all datasets\n",
        "tokens_train = tokenize_and_encode(train_text)\n",
        "tokens_val = tokenize_and_encode(val_text)\n",
        "tokens_test = tokenize_and_encode(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyFVIeK7znR7"
      },
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(tokens_train), torch.from_numpy(train_labels.to_numpy()))\n",
        "val_data = TensorDataset(torch.from_numpy(tokens_val), torch.from_numpy(val_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "train_sampler = RandomSampler(train_data)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# DataLoader\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF5Arl4nZ9TW"
      },
      "source": [
        "## Load Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Fol39kZ_lF"
      },
      "source": [
        "# load embedding as a dict\n",
        "def load_embedding(filename):\n",
        "\t# load embedding into memory, skip first line\n",
        "\tfile = open(filename,'r')\n",
        "\tlines = file.readlines()[1:]\n",
        "\tfile.close()\n",
        "\t# create a map of words to vectors\n",
        "\tembedding = dict()\n",
        "\tfor line in lines:\n",
        "\t\tparts = line.split()\n",
        "\t\t# key is string word, value is numpy array for vector\n",
        "\t\tembedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "\treturn embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGechOGVaBW2"
      },
      "source": [
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab, embedding_dim):\n",
        "\t# total vocabulary size plus 0 for unknown words\n",
        "\tvocab_size = len(vocab) + 1\n",
        "\t# define weight matrix dimensions with all 0\n",
        "\tweight_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\t# step vocab, store vectors using the Tokenizer's integer mapping\n",
        "\tfor word, i in vocab.items():\n",
        "\t\tweight_matrix[i] = embedding.get(word)\n",
        "\n",
        "\treturn weight_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqmWnnIRaDGW"
      },
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape[0], weights_matrix.shape[1]\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "    # emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDOxCeHIqrdP"
      },
      "source": [
        "# load word2vec embedding from file\n",
        "raw_embedding_word2vec = load_embedding('Data/embedding_word2vec.txt')\n",
        "# get vectors in the right order\n",
        "embedding_vectors_word2vec = get_weight_matrix(raw_embedding_word2vec, tokenizer.word_index, 300)\n",
        "embedding_vectors_word2vec = np.float32(embedding_vectors_word2vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJJ4VHSyLoU"
      },
      "source": [
        "# load glove embedding from file\n",
        "raw_embedding_glove = load_embedding('Data/glove_twitter_27B_200d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4d377D-8S9D"
      },
      "source": [
        "# get vectors in the right order\n",
        "embedding_vectors_glove = get_weight_matrix(raw_embedding_glove, tokenizer.word_index, 200)\n",
        "embedding_vectors_glove = np.float32(embedding_vectors_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihLs3XS2ElwJ"
      },
      "source": [
        "for arr in embedding_vectors_glove:\n",
        "    for idx, i in enumerate(arr):\n",
        "        if np.isnan(arr[idx]):\n",
        "            arr[idx] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLtDm2zkaEZx"
      },
      "source": [
        "## CNN Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWDZdEDQMl9Q"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, \n",
        "                 n_filters, filter_sizes, output_dim,\n",
        "                 dropout_rate, pre_trained=False, embedding_vectors=None):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        if pre_trained:\n",
        "            self.embedding, num_embeddings, embedding_dim = create_emb_layer(embedding_vectors, True)\n",
        "        else:\n",
        "            # Create word embeddings from the input words\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # Note: ModuleList holds a list of PyTorch nn.Modules.\n",
        "        # Allowing us to pass in n number of filter sizes, thereby creating a convolutional layer for each of them\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = embedding_dim, \n",
        "                                              out_channels = n_filters, \n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        \n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        \n",
        "    def forward(self, text): \n",
        "        '''\n",
        "        Iterates through the filter size applied to each convolutional layer to get convolutional output,\n",
        "        then apply max pooling before concatenating together and passing through the dropout and fully connected layers.\n",
        "\n",
        "        text: contains [batch size, length of sentence]\n",
        "        '''\n",
        "        embedded = self.embedding(text) # [batch size, length of sentence, embedding dimension]\n",
        "        \n",
        "        embedded = embedded.permute(0, 2, 1) # rearrange to get [batch size, embedding dimension, length of  sentence]\n",
        "    \n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs] # [batch size, n_filters, length of sentence - filter_size of convu layer + 1]\n",
        "        \n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved] # [batch size, n_filters] for each convu layer\n",
        "        \n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1)) # [batch size, n_filters * len(filter_sizes)]\n",
        "            \n",
        "        return self.fc(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwjLtRVg852"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVjq7SGa0x12"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "embedding_dim = 300\n",
        "n_filters = 32\n",
        "filter_sizes = [5,6,7,8]\n",
        "output_dim = 1\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b437kYLxIbAR"
      },
      "source": [
        "# Define the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# push to GPU\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ge7q1bCq2-x"
      },
      "source": [
        "### Model 1: No pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bAThTIZabVX",
        "outputId": "1c82b1ac-1048-453d-dcaf-5a7924ee254a"
      },
      "source": [
        "model1 = CNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout_rate, pre_trained=False)\n",
        "\n",
        "print(\"No pre trained embedding weights\")\n",
        "print(model1)\n",
        "print(f'Model 1 has {count_parameters(model1):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No pre trained embedding weights\n",
            "CNN(\n",
            "  (embedding): Embedding(27605, 300)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 32, kernel_size=(5,), stride=(1,))\n",
            "    (1): Conv1d(300, 32, kernel_size=(6,), stride=(1,))\n",
            "    (2): Conv1d(300, 32, kernel_size=(7,), stride=(1,))\n",
            "    (3): Conv1d(300, 32, kernel_size=(8,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Model 1 has 8,531,357 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY886rb5rcN2"
      },
      "source": [
        "### Model 2: Word2Vec pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feqmNOqqrBNa",
        "outputId": "09d2a036-07f8-4025-9709-009b4ffe0c81"
      },
      "source": [
        "model2 = CNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout_rate, \n",
        "             pre_trained=True, embedding_vectors=embedding_vectors_word2vec)\n",
        "model2.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_word2vec))\n",
        "\n",
        "print(\"With Word2Vec pre trained embedding weights\")\n",
        "print(model2)\n",
        "print(f'Model 2 has {count_parameters(model2):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Word2Vec pre trained embedding weights\n",
            "CNN(\n",
            "  (embedding): Embedding(27605, 300)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 32, kernel_size=(5,), stride=(1,))\n",
            "    (1): Conv1d(300, 32, kernel_size=(6,), stride=(1,))\n",
            "    (2): Conv1d(300, 32, kernel_size=(7,), stride=(1,))\n",
            "    (3): Conv1d(300, 32, kernel_size=(8,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Model 2 has 249,857 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Si7ya0Ywt4o"
      },
      "source": [
        "### Model 3: gloVe Twitter dataset (200d) pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIcjNVMo48O6",
        "outputId": "c24e5e15-1cec-4a30-c729-6713588eb68f"
      },
      "source": [
        "model3 = CNN(vocab_size, 200, n_filters, filter_sizes, output_dim, dropout_rate, \n",
        "             pre_trained=True, embedding_vectors=embedding_vectors_glove)\n",
        "model3.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_glove))\n",
        "\n",
        "print(\"With gloVe pre trained embedding weights\")\n",
        "print(model3)\n",
        "print(f'Model 3 has {count_parameters(model3):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With gloVe pre trained embedding weights\n",
            "CNN(\n",
            "  (embedding): Embedding(27605, 200)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(200, 32, kernel_size=(5,), stride=(1,))\n",
            "    (1): Conv1d(200, 32, kernel_size=(6,), stride=(1,))\n",
            "    (2): Conv1d(200, 32, kernel_size=(7,), stride=(1,))\n",
            "    (3): Conv1d(200, 32, kernel_size=(8,), stride=(1,))\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Model 3 has 166,657 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZXm5HZvarPw"
      },
      "source": [
        "## Helper functions to train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcFGCaZMtURE"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPL0Sn5n4gwf"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches of train data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        # batch = [r.to(device) for r in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for current batch\n",
        "        preds = model(inputs).squeeze(1)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # compute accuracy\n",
        "        acc = binary_accuracy(preds, labels)\n",
        "        \n",
        "        # add on to the total accuracy\n",
        "        total_accuracy += acc.item()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # compute the training acc of the epoch\n",
        "    avg_acc = total_accuracy / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    # returns the loss, accuracy and predictions\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em-HIjbL7Xw4"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        # batch = [t.to(device) for t in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(inputs).squeeze(1)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            acc = binary_accuracy(preds, labels)\n",
        "\n",
        "            total_accuracy += acc.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # compute the validation acc of the epoch\n",
        "    avg_acc = total_accuracy / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIlMqjaxp5HE"
      },
      "source": [
        "## Model 1: No pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia -smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i-Cin3_UL1u",
        "outputId": "ddb96b4d-ccba-4bd0-ce20-0831c18bf5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEs5tvDtq0tJ"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model1.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/cnn_model_1_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZbaGS-KawHG"
      },
      "source": [
        "### Train and Evaluate Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtnlXz7G8uWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb814a59-e071-4a7b-d4df-7b4b380fb767"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model1_train_losses = []\n",
        "model1_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model1_train_accuracies = []\n",
        "model1_valid_accuracies = []\n",
        "\n",
        "train_on_gpu = True\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model1_train_losses.append(train_loss)\n",
        "    model1_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model1_train_accuracies.append(train_acc)\n",
        "    model1_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.297\n",
            "Validation Loss: 0.285\n",
            "\n",
            "Training Accuracy: 0.882\n",
            "Validation Accuracy: 0.887\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.281\n",
            "Validation Loss: 0.275\n",
            "\n",
            "Training Accuracy: 0.889\n",
            "Validation Accuracy: 0.892\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.267\n",
            "Validation Loss: 0.266\n",
            "\n",
            "Training Accuracy: 0.895\n",
            "Validation Accuracy: 0.895\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.256\n",
            "Validation Loss: 0.260\n",
            "\n",
            "Training Accuracy: 0.900\n",
            "Validation Accuracy: 0.897\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.247\n",
            "Validation Loss: 0.254\n",
            "\n",
            "Training Accuracy: 0.904\n",
            "Validation Accuracy: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEe3hMUS9h1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d14c74-2ec1-4700-8423-e8ec450681b0"
      },
      "source": [
        "# load weights of best model cnn\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4OXpIf1bAs1"
      },
      "source": [
        "### Run trained model 1 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyJkRvCZaMy"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoONBIio9sYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52686246-f400-4ae9-98de-9d32ea2893ea"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds = model(inputs).squeeze(1)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(torch.sigmoid(preds.squeeze()))  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aStYKTyA9xlO"
      },
      "source": [
        "### Model 1 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYBh7B8q9we8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdba8f6-5be7-4368-ca01-96db914c5082"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9067    0.9394    0.9228     10744\n",
            "           1     0.8991    0.8482    0.8729      6839\n",
            "\n",
            "    accuracy                         0.9039     17583\n",
            "   macro avg     0.9029    0.8938    0.8979     17583\n",
            "weighted avg     0.9038    0.9039    0.9034     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9zXIbS7IEJk"
      },
      "source": [
        "model_1_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_1_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_1_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_1_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23h6WR6AqGz6"
      },
      "source": [
        "## Model 2: Word2Vec pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTRFx_nsrVU5"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model2.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/cnn_model_2_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_O7wRacr7xA"
      },
      "source": [
        "### Train and Evaluate Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgRteRkpr_Le",
        "outputId": "ba1e9d35-0a7e-4197-e871-0c2afa1fc527"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model2_train_losses = []\n",
        "model2_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model2_train_accuracies = []\n",
        "model2_valid_accuracies = []\n",
        "\n",
        "train_on_gpu = True\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model2_train_losses.append(train_loss)\n",
        "    model2_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model2_train_accuracies.append(train_acc)\n",
        "    model2_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.320\n",
            "Validation Loss: 0.250\n",
            "\n",
            "Training Accuracy: 0.877\n",
            "Validation Accuracy: 0.903\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.244\n",
            "Validation Loss: 0.234\n",
            "\n",
            "Training Accuracy: 0.905\n",
            "Validation Accuracy: 0.910\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.233\n",
            "Validation Loss: 0.227\n",
            "\n",
            "Training Accuracy: 0.910\n",
            "Validation Accuracy: 0.912\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.226\n",
            "Validation Loss: 0.222\n",
            "\n",
            "Training Accuracy: 0.913\n",
            "Validation Accuracy: 0.913\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.221\n",
            "Validation Loss: 0.219\n",
            "\n",
            "Training Accuracy: 0.915\n",
            "Validation Accuracy: 0.914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0p_xNlsD82",
        "outputId": "d21907ec-2cdd-49a5-e375-7ac53c35c0a2"
      },
      "source": [
        "# load weights of best model cnn\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glMQbD6jr-fy"
      },
      "source": [
        "### Run trained model 2 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deBnj0KxsJ-9"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iB1_P1VsKi9",
        "outputId": "9af1f6d6-6259-4d7c-df80-d96463c1691c"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds = model(inputs).squeeze(1)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(torch.sigmoid(preds.squeeze()))  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6obPM6vsQse"
      },
      "source": [
        "### Model 2 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d91i89HhsNA7",
        "outputId": "7beeb0c8-9b8e-4353-b773-0bcd5f9aaf65"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9319    0.9338    0.9329     10744\n",
            "           1     0.8957    0.8928    0.8943      6839\n",
            "\n",
            "    accuracy                         0.9179     17583\n",
            "   macro avg     0.9138    0.9133    0.9136     17583\n",
            "weighted avg     0.9178    0.9179    0.9179     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2WDVjS7H-iA"
      },
      "source": [
        "model_2_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_2_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_2_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_2_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe3SQIS8DLfG"
      },
      "source": [
        "## Model 3: gloVe Twitter dataset (200d) pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpdsJZFCDKXu"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model3.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/cnn_model_3_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QANWA5jDUTr"
      },
      "source": [
        "### Train and Evaluate Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO58cqnRDXvb",
        "outputId": "e2c55d5d-a4c3-4c5c-8adf-ccee2b871d1f"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model3_train_losses = []\n",
        "model3_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model3_train_accuracies = []\n",
        "model3_valid_accuracies = []\n",
        "\n",
        "train_on_gpu = True\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model3_train_losses.append(train_loss)\n",
        "    model3_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model3_train_accuracies.append(train_acc)\n",
        "    model3_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.498\n",
            "Validation Loss: 0.377\n",
            "\n",
            "Training Accuracy: 0.807\n",
            "Validation Accuracy: 0.860\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.347\n",
            "Validation Loss: 0.320\n",
            "\n",
            "Training Accuracy: 0.863\n",
            "Validation Accuracy: 0.874\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.311\n",
            "Validation Loss: 0.297\n",
            "\n",
            "Training Accuracy: 0.874\n",
            "Validation Accuracy: 0.881\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.292\n",
            "Validation Loss: 0.283\n",
            "\n",
            "Training Accuracy: 0.883\n",
            "Validation Accuracy: 0.886\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.280\n",
            "Validation Loss: 0.274\n",
            "\n",
            "Training Accuracy: 0.889\n",
            "Validation Accuracy: 0.891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ArWKi-DdFZ",
        "outputId": "9aa1ec39-d082-431f-bc2f-67aba37e37e0"
      },
      "source": [
        "# load weights of best model cnn\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7OOVTDhDgPN"
      },
      "source": [
        "### Run trained model 3 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF2jYM65Dh1y"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF0fHehYDlTo",
        "outputId": "c1f7afee-e365-4819-d524-d4842687feb6"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds = model(inputs).squeeze(1)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(torch.sigmoid(preds.squeeze()))  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHuNlnLHDsf4"
      },
      "source": [
        "### Model 3 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoODgoNQDnmg",
        "outputId": "58e985e3-6cfd-4e26-9f86-358994449774"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9085    0.9205    0.9145     10744\n",
            "           1     0.8725    0.8544    0.8633      6839\n",
            "\n",
            "    accuracy                         0.8948     17583\n",
            "   macro avg     0.8905    0.8874    0.8889     17583\n",
            "weighted avg     0.8945    0.8948    0.8946     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnX9VbBND3Ke"
      },
      "source": [
        "model_3_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_3_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_3_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_3_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQMG7NA2G9Qj"
      },
      "source": [
        "## Comparison across 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-IO4Lp5G8E4",
        "outputId": "64219746-c781-45c7-fe5f-1c7f00a986fa"
      },
      "source": [
        "table = PrettyTable()\n",
        "table.field_names = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "table.add_row(['CNN without pre trained embedding weights', \n",
        "               format(model_1_test_accuracy_score, '.4f'), \n",
        "               format(model_1_test_precision_score, '.4f'), \n",
        "               format(model_1_test_recall_score, '.4f'), \n",
        "               format(model_1_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['CNN with Word2Vec pre trained embedding weights', \n",
        "               format(model_2_test_accuracy_score, '.4f'), \n",
        "               format(model_2_test_precision_score, '.4f'), \n",
        "               format(model_2_test_recall_score, '.4f'), \n",
        "               format(model_2_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['CNN with gloVe Twitter (200d) pre trained embedding weights', \n",
        "               format(model_3_test_accuracy_score, '.4f'), \n",
        "               format(model_3_test_precision_score, '.4f'), \n",
        "               format(model_3_test_recall_score, '.4f'), \n",
        "               format(model_3_test_f1_score, '.4f')])\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|                            Model                            | Accuracy | Precision | Recall | F1 Score |\n",
            "+-------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|          CNN without pre trained embedding weights          |  0.9039  |   0.8991  | 0.8482 |  0.8729  |\n",
            "|       CNN with Word2Vec pre trained embedding weights       |  0.9179  |   0.8957  | 0.8928 |  0.8943  |\n",
            "| CNN with gloVe Twitter (200d) pre trained embedding weights |  0.8948  |   0.8725  | 0.8544 |  0.8633  |\n",
            "+-------------------------------------------------------------+----------+-----------+--------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Um_n6FBiHwTX",
        "outputId": "7234c061-cfe3-4a85-d7c2-ac5ef499f020"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(model1_train_accuracies, \"r-\")\n",
        "plt.plot(model1_valid_accuracies, \"r--\")\n",
        "plt.plot(model2_train_accuracies, \"b-\")\n",
        "plt.plot(model2_valid_accuracies, \"b--\")\n",
        "plt.plot(model3_train_accuracies, \"g-\")\n",
        "plt.plot(model3_valid_accuracies, \"g--\")\n",
        "plt.title('Comparison of accuracies across CNN models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train (model 1)', 'validation (model 1)', 'train (model 2)', 'validation (model 2)', 'train (model 3)', 'validation (model 3)'], \n",
        "           bbox_to_anchor=(1, 1))\n",
        "           #loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K30XCoiOJCU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}