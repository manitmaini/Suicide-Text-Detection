{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFCedZK5tjKb"
      },
      "source": [
        "# Long Short-Term Memory (LSTM)\n",
        "This notebook aims to apply the LSTM model to perform text classification and detect suicidal text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsC8c2KgvVYc",
        "outputId": "c9e0b116-bcf7-4c0c-9854-c16987d74b47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z25kuEC1uHDX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, f1_score, precision_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWH7zlQttGK4"
      },
      "source": [
        "# Specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo6PuOIbSgTH",
        "outputId": "d7840885-fdd5-4a97-ae5d-7ecad09deaac"
      },
      "source": [
        "# Change to your own directory\n",
        "try: \n",
        "    os.chdir(\"/content/drive/MyDrive/Suicide Project\")\n",
        "    print(\"Directory changed\")\n",
        "except OSError:\n",
        "    print(\"Error: Can't change the Current Working Directory\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory changed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz6Ta9uK1PSi"
      },
      "source": [
        "## Define constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqtxDrajt1V1"
      },
      "source": [
        "# Define constants\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-5\n",
        "SEED = 4222"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHw7phON1RUm"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T98zLXPUvjrp",
        "outputId": "88b9f27c-dc92-4ff1-e362-3a8ec0ad1be6"
      },
      "source": [
        "# Load dataset\n",
        "suicide_detection_df = pd.read_csv('Data/suicide_detection_final_cleaned.csv', header=0)\n",
        "suicide_detection_df.drop(columns=['text'], axis=1, inplace=True)\n",
        "suicide_detection_df = suicide_detection_df.rename(columns={\"cleaned_text\": \"text\"})\n",
        "classes = {\"suicide\": 1, \"non-suicide\": 0}\n",
        "suicide_detection_df = suicide_detection_df.replace({\"class\": classes})\n",
        "suicide_detection_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class                                               text\n",
              "0      1  sex wife threaten suicide recently leave wife ...\n",
              "1      0  weird not affect compliment come know girl fee...\n",
              "2      0      finally hear bad year swear fuck god annoying\n",
              "3      1                            need help help cry hard\n",
              "4      1                       end tonight not anymore quit"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53811505-63b7-426c-abcb-d58f9efb98b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sex wife threaten suicide recently leave wife ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>weird not affect compliment come know girl fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>finally hear bad year swear fuck god annoying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>need help help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53811505-63b7-426c-abcb-d58f9efb98b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53811505-63b7-426c-abcb-d58f9efb98b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53811505-63b7-426c-abcb-d58f9efb98b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9LkTWXY1L63"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I85QRroxx6v-"
      },
      "source": [
        "# Split dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(suicide_detection_df['text'], suicide_detection_df['class'],\n",
        "                                                                    random_state=SEED,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=suicide_detection_df['class'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=SEED,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMbclgR567PT"
      },
      "source": [
        "## Max Length and Number of vocab words in Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pSrItzF7Pjv",
        "outputId": "95c6af84-84a1-4a4d-ba12-f863cff9b548"
      },
      "source": [
        "max_length = max([len(s.split()) for s in train_text])\n",
        "max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gP9mxTY6-OK"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "067jN-5z1UDU"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkFNT4pG6Cer"
      },
      "source": [
        "def tokenize_and_encode(text, max_length=62):\n",
        "    \"\"\"Tokenize and encode sequences.\"\"\"\n",
        "\n",
        "    # sequence encode\n",
        "    encoded_docs = tokenizer.texts_to_sequences(text)\n",
        "    # pad sequences\n",
        "    padded_sequence = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "\n",
        "    return padded_sequence\n",
        "\n",
        "# Tokenize and encode sequences in all datasets\n",
        "tokens_train = tokenize_and_encode(train_text)\n",
        "tokens_val = tokenize_and_encode(val_text)\n",
        "tokens_test = tokenize_and_encode(test_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyFVIeK7znR7"
      },
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(tokens_train), torch.from_numpy(train_labels.to_numpy()))\n",
        "val_data = TensorDataset(torch.from_numpy(tokens_val), torch.from_numpy(val_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "train_sampler = RandomSampler(train_data)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# DataLoader\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg3zcp-CNAdx"
      },
      "source": [
        "## Load Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZwbdgt-QsTH"
      },
      "source": [
        "# load embedding as a dict\n",
        "def load_embedding(filename):\n",
        "\t# load embedding into memory, skip first line\n",
        "\tfile = open(filename,'r')\n",
        "\tlines = file.readlines()[1:]\n",
        "\tfile.close()\n",
        "\t# create a map of words to vectors\n",
        "\tembedding = dict()\n",
        "\tfor line in lines:\n",
        "\t\tparts = line.split()\n",
        "\t\t# key is string word, value is numpy array for vector\n",
        "\t\tembedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "\treturn embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZP9hFjFQ0zk"
      },
      "source": [
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab, embedding_dim):\n",
        "\t# total vocabulary size plus 0 for unknown words\n",
        "\tvocab_size = len(vocab) + 1\n",
        "\t# define weight matrix dimensions with all 0\n",
        "\tweight_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\t# step vocab, store vectors using the Tokenizer's integer mapping\n",
        "\tfor word, i in vocab.items():\n",
        "\t\tweight_matrix[i] = embedding.get(word)\n",
        "\n",
        "\treturn weight_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khl9UdMiafhf"
      },
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape[0], weights_matrix.shape[1]\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': torch.from_numpy(weights_matrix)})\n",
        "    # emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix))\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVjq7SGa0x12"
      },
      "source": [
        "# load word2vec embedding from file\n",
        "raw_embedding_word2vec = load_embedding('Data/embedding_word2vec.txt') # 'Data/embedding_word2vec_1.txt'\n",
        "# get vectors in the right order\n",
        "embedding_vectors_word2vec = get_weight_matrix(raw_embedding_word2vec, tokenizer.word_index, 300)\n",
        "embedding_vectors_word2vec = np.float32(embedding_vectors_word2vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNeVnQ11aGs"
      },
      "source": [
        "# load glove embedding from file\n",
        "raw_embedding_glove = load_embedding('Data/glove_twitter_27B_200d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAaVE4wObfVX"
      },
      "source": [
        "# get vectors in the right order\n",
        "embedding_vectors_glove = get_weight_matrix(raw_embedding_glove, tokenizer.word_index, 200)\n",
        "embedding_vectors_glove = np.float32(embedding_vectors_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5V3mNuVWILb"
      },
      "source": [
        "for arr in embedding_vectors_glove:\n",
        "    for idx, i in enumerate(arr):\n",
        "        if np.isnan(arr[idx]):\n",
        "            arr[idx] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksRMxiEN0iL7"
      },
      "source": [
        "## LSTM Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zlwS1uu0UmF"
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, \n",
        "                 embedding_dim, hidden_dim, n_layers, \n",
        "                 dropout_rate, pre_trained=False, embedding_vectors=None):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        if pre_trained:\n",
        "            self.embedding, num_embeddings, embedding_dim = create_emb_layer(embedding_vectors, True)\n",
        "        else:\n",
        "            # Create word embeddings from the input words\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=dropout_rate, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3) # dropout_rate\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CSeRolmCrmq"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPaYMhO0e2w"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "embedding_dim = 300\n",
        "hidden_dim = 128\n",
        "output_size = 1\n",
        "n_layers = 2\n",
        "dropout = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ougK6aMHTudz"
      },
      "source": [
        "# Define the loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# push to GPU\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1jQ90BX0ps3"
      },
      "source": [
        "### Model 1: No pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK3jX90Iq_dG",
        "outputId": "9b4705cc-186f-4083-8fa5-9318ddd15071"
      },
      "source": [
        "model1 = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout)\n",
        "\n",
        "print(\"No pre trained embedding weights\")\n",
        "print(model1)\n",
        "\n",
        "print(f'Model 1 has {count_parameters(model1):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(27605, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 1 has 8,633,885 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muPf3hPG1DD_"
      },
      "source": [
        "### Model 2: Word2Vec pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3de5WCp0wPO",
        "outputId": "84fe71a8-a396-4b56-82e6-a7144e1b0181"
      },
      "source": [
        "model2 = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout, \n",
        "                       pre_trained=True, embedding_vectors=embedding_vectors_word2vec)\n",
        "model2.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_word2vec))\n",
        "\n",
        "print(\"With Word2Vec pre trained embedding weights\")\n",
        "print(model2)\n",
        "\n",
        "print(f'Model 2 has {count_parameters(model2):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Word2Vec pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(27605, 300)\n",
            "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 2 has 352,385 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zw28M_f1cy0"
      },
      "source": [
        "### Model 3: glove Twitter dataset (200d) pre trained embedding weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBSBiN0y1orJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a6c9e8-35db-4882-c984-99066e5f942b"
      },
      "source": [
        "model3 = SentimentLSTM(vocab_size, output_size, 200, hidden_dim, n_layers, dropout, \n",
        "                       pre_trained=True, embedding_vectors=embedding_vectors_glove)\n",
        "model3.embedding.weight.data.copy_(torch.from_numpy(embedding_vectors_glove))\n",
        "\n",
        "print(\"With gloVe pre trained embedding weights\")\n",
        "print(model3)\n",
        "\n",
        "print(f'Model 3 has {count_parameters(model3):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With gloVe pre trained embedding weights\n",
            "SentimentLSTM(\n",
            "  (embedding): Embedding(27605, 200)\n",
            "  (lstm): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n",
            "Model 3 has 301,185 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srVEIRzr0wMn"
      },
      "source": [
        "## Helper functions to train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7pWyXSVdvTq"
      },
      "source": [
        "def binary_accuracy(preds, labels):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = preds.eq(labels.float().view_as(preds))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct = np.sum(correct)\n",
        "\n",
        "    acc = num_correct/len(correct)\n",
        "\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPL0Sn5n4gwf"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches of train data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
        "        \n",
        "        # push the batch to gpu\n",
        "        # batch = [r.to(device) for r in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        # initialize hidden state\n",
        "        h = model.init_hidden(len(inputs))\n",
        "\n",
        "        # move to gpu\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Create new variables for the hidden state\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for current batch\n",
        "        preds, h = model(inputs, h)\n",
        "        \n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "\n",
        "        # compute accuracy\n",
        "        acc = binary_accuracy(preds, labels)\n",
        "\n",
        "        # add on to the total accuracy\n",
        "        total_accuracy += acc.item()\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # compute the training acc of the epoch\n",
        "    avg_acc = total_accuracy / len(train_dataloader)\n",
        "\n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    # returns the loss, accuracy and predictions\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em-HIjbL7Xw4"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step, batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        # batch = [t.to(device) for t in batch]\n",
        "\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "        # initialize hidden state\n",
        "        val_h = model.init_hidden(len(inputs))\n",
        "\n",
        "        # move to gpu\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Create new variables for the hidden state\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds, val_h = model(inputs, val_h)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = criterion(preds.squeeze(), labels.float())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            acc = binary_accuracy(preds, labels)\n",
        "\n",
        "            total_accuracy += acc.item()\n",
        "            \n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            \n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # compute the validation acc of the epoch\n",
        "    avg_acc = total_accuracy / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, avg_acc, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8SxflsQ00nX"
      },
      "source": [
        "## Model 1: No pre trained embedding weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44yI5mpf2W8v"
      },
      "source": [
        "### Train and Evaluate Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRZcWqnR1A-c"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = optim.Adam(model1.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model1.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/lstm_model_1_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtnlXz7G8uWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00075549-3acb-46af-c116-e5083019257c"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model1_train_losses = []\n",
        "model1_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model1_train_accuracies = []\n",
        "model1_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model1_train_losses.append(train_loss)\n",
        "    model1_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model1_train_accuracies.append(train_acc)\n",
        "    model1_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.684\n",
            "Validation Loss: 0.661\n",
            "\n",
            "Training Accuracy: 0.676\n",
            "Validation Accuracy: 0.739\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.657\n",
            "Validation Loss: 0.651\n",
            "\n",
            "Training Accuracy: 0.747\n",
            "Validation Accuracy: 0.761\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.647\n",
            "Validation Loss: 0.646\n",
            "\n",
            "Training Accuracy: 0.769\n",
            "Validation Accuracy: 0.789\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.623\n",
            "Validation Loss: 0.608\n",
            "\n",
            "Training Accuracy: 0.827\n",
            "Validation Accuracy: 0.860\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.610\n",
            "Validation Loss: 0.604\n",
            "\n",
            "Training Accuracy: 0.862\n",
            "Validation Accuracy: 0.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEe3hMUS9h1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8d1318-4c10-4f2e-beae-260f0d236c0f"
      },
      "source": [
        "# load weights of best model lstm\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo0sgX-c04fe"
      },
      "source": [
        "### Run trained model 1 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyJkRvCZaMy"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoONBIio9sYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2ac417-3b53-4d91-d088-eaac72ca3d9a"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aStYKTyA9xlO"
      },
      "source": [
        "### Model 1 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYBh7B8q9we8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ecd643-aec7-4f5a-f4b9-9deb4b789afd"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8650    0.9376    0.8999     10744\n",
            "           1     0.8871    0.7701    0.8245      6839\n",
            "\n",
            "    accuracy                         0.8725     17583\n",
            "   macro avg     0.8761    0.8539    0.8622     17583\n",
            "weighted avg     0.8736    0.8725    0.8706     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feNqNTXhV7Rb"
      },
      "source": [
        "model_1_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_1_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_1_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_1_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjym_eS725B9"
      },
      "source": [
        "## Model 2: Word2Vec pre trained embedding weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2AZT3Ni3Bb9"
      },
      "source": [
        "### Train and Evaluate Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmIHVBxE2vf9"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model2.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/lstm_model_2_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czajK5fy3FUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212182bb-93a3-4cd0-eedb-e9b6976d35fd"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model2_train_losses = []\n",
        "model2_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model2_train_accuracies = []\n",
        "model2_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model2_train_losses.append(train_loss)\n",
        "    model2_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model2_train_accuracies.append(train_acc)\n",
        "    model2_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.653\n",
            "Validation Loss: 0.600\n",
            "\n",
            "Training Accuracy: 0.764\n",
            "Validation Accuracy: 0.895\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.596\n",
            "Validation Loss: 0.593\n",
            "\n",
            "Training Accuracy: 0.898\n",
            "Validation Accuracy: 0.908\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.590\n",
            "Validation Loss: 0.589\n",
            "\n",
            "Training Accuracy: 0.905\n",
            "Validation Accuracy: 0.909\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 0.588\n",
            "\n",
            "Training Accuracy: 0.908\n",
            "Validation Accuracy: 0.912\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.587\n",
            "Validation Loss: 0.589\n",
            "\n",
            "Training Accuracy: 0.910\n",
            "Validation Accuracy: 0.896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM6QRH7Q3Is8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aea4b31-5035-4b91-c4dd-262bcacfc5eb"
      },
      "source": [
        "# load weights of best model lstm\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTj_lWHD3Bj2"
      },
      "source": [
        "### Run trained model 2 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAse2kCc3P7N"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkSR7Y4a3Szj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0397fe-5e2e-4279-a426-03c62b6c30fb"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWh7dcXY3WUZ"
      },
      "source": [
        "### Model 2 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNPJCI9c3Yhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb50a507-d482-4085-b3df-e1c4012f2e4b"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9212    0.9469    0.9339     10744\n",
            "           1     0.9128    0.8728    0.8924      6839\n",
            "\n",
            "    accuracy                         0.9181     17583\n",
            "   macro avg     0.9170    0.9099    0.9131     17583\n",
            "weighted avg     0.9180    0.9181    0.9177     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmZdtHvHV9ni"
      },
      "source": [
        "model_2_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_2_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_2_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_2_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtoMvrBX30g7"
      },
      "source": [
        "## Model 3: gloVe Twitter dataset (200d) pre trained embedding weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k09La3b4Fir"
      },
      "source": [
        "### Train and Evaluate Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-uPRdZt38VV"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# push to GPU\n",
        "model = model3.to(device)\n",
        "\n",
        "MODEL_WEIGHTS_PATH = 'Models/lstm_model_3_saved_weights.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSN1wQRQ4H-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40988fd7-cc5a-4e2b-c966-00a9aa18c7ea"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "model3_train_losses = []\n",
        "model3_valid_losses = []\n",
        "\n",
        "# empty lists to store training and validation acc of each epoch\n",
        "model3_train_accuracies = []\n",
        "model3_valid_accuracies = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch+1, EPOCHS))\n",
        "    \n",
        "    # train model\n",
        "    train_loss, train_acc, _ = train()\n",
        "\n",
        "    # evaluate model\n",
        "    valid_loss, valid_acc, _ = evaluate()\n",
        "\n",
        "    # save best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "    \n",
        "    # append training and validation loss\n",
        "    model3_train_losses.append(train_loss)\n",
        "    model3_valid_losses.append(valid_loss)\n",
        "\n",
        "    # append training and validation acc\n",
        "    model3_train_accuracies.append(train_acc)\n",
        "    model3_valid_accuracies.append(valid_acc)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    print(f'\\nTraining Accuracy: {train_acc:.3f}')\n",
        "    print(f'Validation Accuracy: {valid_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.670\n",
            "Validation Loss: 0.623\n",
            "\n",
            "Training Accuracy: 0.709\n",
            "Validation Accuracy: 0.850\n",
            "\n",
            " Epoch 2 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.606\n",
            "\n",
            "Training Accuracy: 0.859\n",
            "Validation Accuracy: 0.871\n",
            "\n",
            " Epoch 3 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.605\n",
            "Validation Loss: 0.603\n",
            "\n",
            "Training Accuracy: 0.872\n",
            "Validation Accuracy: 0.873\n",
            "\n",
            " Epoch 4 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.602\n",
            "Validation Loss: 0.599\n",
            "\n",
            "Training Accuracy: 0.878\n",
            "Validation Accuracy: 0.883\n",
            "\n",
            " Epoch 5 / 5\n",
            "Batch    50 of 4,396.\n",
            "Batch   100 of 4,396.\n",
            "Batch   150 of 4,396.\n",
            "Batch   200 of 4,396.\n",
            "Batch   250 of 4,396.\n",
            "Batch   300 of 4,396.\n",
            "Batch   350 of 4,396.\n",
            "Batch   400 of 4,396.\n",
            "Batch   450 of 4,396.\n",
            "Batch   500 of 4,396.\n",
            "Batch   550 of 4,396.\n",
            "Batch   600 of 4,396.\n",
            "Batch   650 of 4,396.\n",
            "Batch   700 of 4,396.\n",
            "Batch   750 of 4,396.\n",
            "Batch   800 of 4,396.\n",
            "Batch   850 of 4,396.\n",
            "Batch   900 of 4,396.\n",
            "Batch   950 of 4,396.\n",
            "Batch 1,000 of 4,396.\n",
            "Batch 1,050 of 4,396.\n",
            "Batch 1,100 of 4,396.\n",
            "Batch 1,150 of 4,396.\n",
            "Batch 1,200 of 4,396.\n",
            "Batch 1,250 of 4,396.\n",
            "Batch 1,300 of 4,396.\n",
            "Batch 1,350 of 4,396.\n",
            "Batch 1,400 of 4,396.\n",
            "Batch 1,450 of 4,396.\n",
            "Batch 1,500 of 4,396.\n",
            "Batch 1,550 of 4,396.\n",
            "Batch 1,600 of 4,396.\n",
            "Batch 1,650 of 4,396.\n",
            "Batch 1,700 of 4,396.\n",
            "Batch 1,750 of 4,396.\n",
            "Batch 1,800 of 4,396.\n",
            "Batch 1,850 of 4,396.\n",
            "Batch 1,900 of 4,396.\n",
            "Batch 1,950 of 4,396.\n",
            "Batch 2,000 of 4,396.\n",
            "Batch 2,050 of 4,396.\n",
            "Batch 2,100 of 4,396.\n",
            "Batch 2,150 of 4,396.\n",
            "Batch 2,200 of 4,396.\n",
            "Batch 2,250 of 4,396.\n",
            "Batch 2,300 of 4,396.\n",
            "Batch 2,350 of 4,396.\n",
            "Batch 2,400 of 4,396.\n",
            "Batch 2,450 of 4,396.\n",
            "Batch 2,500 of 4,396.\n",
            "Batch 2,550 of 4,396.\n",
            "Batch 2,600 of 4,396.\n",
            "Batch 2,650 of 4,396.\n",
            "Batch 2,700 of 4,396.\n",
            "Batch 2,750 of 4,396.\n",
            "Batch 2,800 of 4,396.\n",
            "Batch 2,850 of 4,396.\n",
            "Batch 2,900 of 4,396.\n",
            "Batch 2,950 of 4,396.\n",
            "Batch 3,000 of 4,396.\n",
            "Batch 3,050 of 4,396.\n",
            "Batch 3,100 of 4,396.\n",
            "Batch 3,150 of 4,396.\n",
            "Batch 3,200 of 4,396.\n",
            "Batch 3,250 of 4,396.\n",
            "Batch 3,300 of 4,396.\n",
            "Batch 3,350 of 4,396.\n",
            "Batch 3,400 of 4,396.\n",
            "Batch 3,450 of 4,396.\n",
            "Batch 3,500 of 4,396.\n",
            "Batch 3,550 of 4,396.\n",
            "Batch 3,600 of 4,396.\n",
            "Batch 3,650 of 4,396.\n",
            "Batch 3,700 of 4,396.\n",
            "Batch 3,750 of 4,396.\n",
            "Batch 3,800 of 4,396.\n",
            "Batch 3,850 of 4,396.\n",
            "Batch 3,900 of 4,396.\n",
            "Batch 3,950 of 4,396.\n",
            "Batch 4,000 of 4,396.\n",
            "Batch 4,050 of 4,396.\n",
            "Batch 4,100 of 4,396.\n",
            "Batch 4,150 of 4,396.\n",
            "Batch 4,200 of 4,396.\n",
            "Batch 4,250 of 4,396.\n",
            "Batch 4,300 of 4,396.\n",
            "Batch 4,350 of 4,396.\n",
            "\n",
            "Evaluating...\n",
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n",
            "\n",
            "Training Loss: 0.599\n",
            "Validation Loss: 0.598\n",
            "\n",
            "Training Accuracy: 0.882\n",
            "Validation Accuracy: 0.887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr5K5iCH4NJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66966e65-db29-4fb8-d0b3-6335f95e700a"
      },
      "source": [
        "# load weights of best model lstm\n",
        "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1SmpDtY4OYm"
      },
      "source": [
        "### Run trained model 3 on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kftlg6aB4Ts_"
      },
      "source": [
        "# create Tensor datasets\n",
        "test_data = TensorDataset(torch.from_numpy(tokens_test), torch.from_numpy(test_labels.to_numpy()))\n",
        "\n",
        "# Sampler for sampling the data\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# DataLoader\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_URc5I4G4UaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc18aa5-2235-4332-f939-13302afe2f28"
      },
      "source": [
        "# empty list to save the model predictions\n",
        "total_preds = []\n",
        "\n",
        "# iterate over batches\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "        print('Batch {:>5,} of {:>5,}.'.format(step, len(test_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [t.to(device) for t in batch]\n",
        "\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "\n",
        "    # initialize hidden state\n",
        "    test_h = model.init_hidden(len(inputs)) # BATCH_SIZE # to discuss!!!!!!!!!\n",
        "\n",
        "    # move to gpu\n",
        "    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # Create new variables for the hidden state\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # model predictions\n",
        "        preds, test_h = model(inputs, test_h)\n",
        "\n",
        "        # convert output probabilities to predicted class (0 or 1)\n",
        "        preds = torch.round(preds.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "\n",
        "        total_preds.append(preds)\n",
        "\n",
        "# reshape the predictions in form of (number of samples, no. of classes)\n",
        "total_preds = np.concatenate(total_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch    50 of   550.\n",
            "Batch   100 of   550.\n",
            "Batch   150 of   550.\n",
            "Batch   200 of   550.\n",
            "Batch   250 of   550.\n",
            "Batch   300 of   550.\n",
            "Batch   350 of   550.\n",
            "Batch   400 of   550.\n",
            "Batch   450 of   550.\n",
            "Batch   500 of   550.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MlXtb-F4Zya"
      },
      "source": [
        "### Model 3 Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpCgyNdJ4c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cd690c-beb9-4f2b-b5fd-c54ac26aa1a4"
      },
      "source": [
        "print(classification_report(test_labels, total_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8892    0.9378    0.9128     10744\n",
            "           1     0.8931    0.8163    0.8530      6839\n",
            "\n",
            "    accuracy                         0.8906     17583\n",
            "   macro avg     0.8912    0.8771    0.8829     17583\n",
            "weighted avg     0.8907    0.8906    0.8896     17583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQOiNuMcWAI5"
      },
      "source": [
        "model_3_test_accuracy_score = accuracy_score(test_labels, total_preds)\n",
        "model_3_test_precision_score = precision_score(test_labels, total_preds)\n",
        "model_3_test_recall_score = recall_score(test_labels, total_preds)\n",
        "model_3_test_f1_score = f1_score(test_labels, total_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKxFyWOyWNlo"
      },
      "source": [
        "## Comparison across 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fO-nP5jWP9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2d020e-cddf-4e79-d46d-b871d0992dd3"
      },
      "source": [
        "table = PrettyTable()\n",
        "table.field_names = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "table.add_row(['LSTM without pre trained embedding weights', \n",
        "               format(model_1_test_accuracy_score, '.4f'), \n",
        "               format(model_1_test_precision_score, '.4f'), \n",
        "               format(model_1_test_recall_score, '.4f'), \n",
        "               format(model_1_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['LSTM with Word2Vec pre trained embedding weights', \n",
        "               format(model_2_test_accuracy_score, '.4f'), \n",
        "               format(model_2_test_precision_score, '.4f'), \n",
        "               format(model_2_test_recall_score, '.4f'), \n",
        "               format(model_2_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['LSTM with gloVe Twitter (200d) pre trained embedding weights', \n",
        "               format(model_3_test_accuracy_score, '.4f'), \n",
        "               format(model_3_test_precision_score, '.4f'), \n",
        "               format(model_3_test_recall_score, '.4f'), \n",
        "               format(model_3_test_f1_score, '.4f')])\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|                            Model                             | Accuracy | Precision | Recall | F1 Score |\n",
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n",
            "|          LSTM without pre trained embedding weights          |  0.8725  |   0.8871  | 0.7701 |  0.8245  |\n",
            "|       LSTM with Word2Vec pre trained embedding weights       |  0.9181  |   0.9128  | 0.8728 |  0.8924  |\n",
            "| LSTM with gloVe Twitter (200d) pre trained embedding weights |  0.8906  |   0.8931  | 0.8163 |  0.8530  |\n",
            "+--------------------------------------------------------------+----------+-----------+--------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b5f-q_TQVlz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "b5c102f2-b1e7-47a1-fd8d-81d31ea2d1ca"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(model1_train_accuracies, \"r-\")\n",
        "plt.plot(model1_valid_accuracies, \"r--\")\n",
        "plt.plot(model2_train_accuracies, \"b-\")\n",
        "plt.plot(model2_valid_accuracies, \"b--\")\n",
        "plt.plot(model3_train_accuracies, \"g-\")\n",
        "plt.plot(model3_valid_accuracies, \"g--\")\n",
        "plt.title('Comparison of accuracies across LSTM models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train (model 1)', 'validation (model 1)', 'train (model 2)', 'validation (model 2)', 'train (model 3)', 'validation (model 3)'], \n",
        "           bbox_to_anchor=(1, 1))\n",
        "           #loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIeoAKtMpo8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}