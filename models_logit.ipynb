{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD6wu3yPBxGy"
      },
      "source": [
        "# Logistic Regression (Logit)\n",
        "This notebook aims to apply the logit model to perform text classification and detect suicidal text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_q3Y1Zc0s7F",
        "outputId": "cda48a8f-6ab6-4c1c-dc5b-2ff959ced21b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgRdNSJElABB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, f1_score, precision_score\n",
        "from collections import Counter\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbqFqlVk26SP"
      },
      "source": [
        "SEED = 4222\n",
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ccDHJwJ7xqa",
        "outputId": "726b54a8-4d5c-4bd5-e107-b1989e27f501"
      },
      "source": [
        "# Change to your own directory\n",
        "try: \n",
        "    os.chdir(\"/content/drive/MyDrive/Suicide Project\")\n",
        "    print(\"Directory changed\")\n",
        "except OSError:\n",
        "    print(\"Error: Can't change the Current Working Directory\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory changed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJWPJjlKk194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3e0ed5f8-a05e-49db-fb23-fd74bfb2596b"
      },
      "source": [
        "# Load dataset\n",
        "suicide_detection_df = pd.read_csv('Data/suicide_detection_final_cleaned.csv', header=0)\n",
        "suicide_detection_df.drop(columns=['text'], axis=1, inplace=True)\n",
        "suicide_detection_df = suicide_detection_df.rename(columns={\"cleaned_text\": \"text\"})\n",
        "classes = {\"suicide\": 1, \"non-suicide\": 0}\n",
        "suicide_detection_df = suicide_detection_df.replace({\"class\": classes})\n",
        "suicide_detection_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class                                               text\n",
              "0      1  sex wife threaten suicide recently leave wife ...\n",
              "1      0  weird not affect compliment come know girl fee...\n",
              "2      0      finally hear bad year swear fuck god annoying\n",
              "3      1                            need help help cry hard\n",
              "4      1                       end tonight not anymore quit"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5286db43-c673-4fde-8984-d941628c9c14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sex wife threaten suicide recently leave wife ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>weird not affect compliment come know girl fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>finally hear bad year swear fuck god annoying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>need help help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5286db43-c673-4fde-8984-d941628c9c14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5286db43-c673-4fde-8984-d941628c9c14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5286db43-c673-4fde-8984-d941628c9c14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3mECsTh9rBR"
      },
      "source": [
        "# Split dataset into train, validation and test sets\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(suicide_detection_df['text'], suicide_detection_df['class'],\n",
        "                                                                    random_state=SEED,\n",
        "                                                                    test_size=0.2,\n",
        "                                                                    stratify=suicide_detection_df['class'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpt9mLVkVuls"
      },
      "source": [
        "## Import vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eauh3LKKU3VL"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load the vocabulary\n",
        "vocab_filename = 'Data/vocab.txt'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze2h2s0lWwNT"
      },
      "source": [
        "## Import Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJM-dD2TVfqn"
      },
      "source": [
        "# load embedding as a dict\n",
        "def load_embedding(filename):\n",
        "\t# load embedding into memory, skip first line\n",
        "\tfile = open(filename,'r')\n",
        "\tlines = file.readlines()[1:]\n",
        "\tfile.close()\n",
        "\t# create a map of words to vectors\n",
        "\tembedding = dict()\n",
        "\tfor line in lines:\n",
        "\t\tparts = line.split()\n",
        "\t\t# key is string word, value is numpy array for vector\n",
        "\t\tembedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "\treturn embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmJ4feCUkPS"
      },
      "source": [
        "### Removing out of vocab words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-h6zgwXUBdI"
      },
      "source": [
        "# clean each line\n",
        "def clean_line(line, vocab):\n",
        "  tokens = line.split()\n",
        "  # filter out tokens not in vocab\n",
        "  tokens_clean = [w for w in tokens if w in vocab]\n",
        "  return [tokens_clean]\n",
        "\n",
        "# clean entire dataset\n",
        "def process_lines(data, vocab):\n",
        "  lines = list()\n",
        "  for i in data:\n",
        "    line = clean_line(i, vocab)\n",
        "    # add lines to list\n",
        "    lines += line\n",
        "  return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGeCgvg7YST7"
      },
      "source": [
        "### Document Vector function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRy16DvXYSV"
      },
      "source": [
        "def document_vector(doc, embeddings):\n",
        "    sentence = list()\n",
        "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
        "    doc = [word for word in doc if word in embeddings.keys()]\n",
        "    for i in doc:\n",
        "      word = embeddings[i]\n",
        "      sentence.append(word)\n",
        "    return np.mean(sentence, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW8JPGjSORlj"
      },
      "source": [
        "# function for all the data\n",
        "def all_documents(df, labels_ori, embeddings):\n",
        "  vec = list()\n",
        "  labels = list()\n",
        "  for i in range(len(df)):\n",
        "    if len(df[i]) == 0:\n",
        "      continue\n",
        "    else:\n",
        "      vec.append(document_vector(df[i], embeddings))\n",
        "      labels.append(labels_ori.values[i])\n",
        "  return vec, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmZYEg86TsMm"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYRd8jX6W--u"
      },
      "source": [
        "word2vec = load_embedding('Data/embedding_word2vec.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBsZllXjQiiG"
      },
      "source": [
        "train_clean = process_lines(train_text, vocab)\n",
        "test_clean = process_lines(test_text, vocab)\n",
        "train_vec, train_labels_new = all_documents(train_clean, train_labels,word2vec)\n",
        "test_vec, test_labels_new = all_documents(test_clean, test_labels, word2vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6vCiY9yQFXn",
        "outputId": "0fe0c18c-7c84-4e8c-875d-7ed94a3cd187"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec, train_labels_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfu8uuUuRNwQ",
        "outputId": "947b83ba-1adf-44de-e35a-cd00a63ac8fc"
      },
      "source": [
        "y_train_pred = lr.predict(train_vec)\n",
        "print('Training set accuracy %s' % accuracy_score(train_labels_new, y_train_pred))\n",
        "print(classification_report(train_labels_new, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy 0.902538034977961\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     85948\n",
            "           1       0.87      0.87      0.87     54712\n",
            "\n",
            "    accuracy                           0.90    140660\n",
            "   macro avg       0.90      0.90      0.90    140660\n",
            "weighted avg       0.90      0.90      0.90    140660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcaf9eVDqp3n",
        "outputId": "64472071-dc9b-44e2-eff6-d58507c65087"
      },
      "source": [
        "y_test_pred = lr.predict(test_vec)\n",
        "print('Test set accuracy %s' % accuracy_score(test_labels_new, y_test_pred))\n",
        "print(classification_report(test_labels_new, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy 0.9043230944254835\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92     21483\n",
            "           1       0.88      0.88      0.88     13677\n",
            "\n",
            "    accuracy                           0.90     35160\n",
            "   macro avg       0.90      0.90      0.90     35160\n",
            "weighted avg       0.90      0.90      0.90     35160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TS2NrNG328R"
      },
      "source": [
        "word2vec_test_accuracy_score = accuracy_score(test_labels_new, y_test_pred)\n",
        "word2vec_test_precision_score = precision_score(test_labels_new, y_test_pred)\n",
        "word2vec_test_recall_score = recall_score(test_labels_new, y_test_pred)\n",
        "word2vec_test_f1_score = f1_score(test_labels_new, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awaSA0qO8Pvl"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KghtIenT8YY4"
      },
      "source": [
        "# load glove embedding from file\n",
        "raw_embedding_glove = load_embedding('Data/glove_twitter_27B_200d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osPAxTfsLHyO"
      },
      "source": [
        "train_clean_glove = process_lines(train_text, raw_embedding_glove.keys())\n",
        "test_clean_glove = process_lines(test_text, raw_embedding_glove.keys())\n",
        "train_vec_glove, train_labels_glove_new = all_documents(train_clean_glove, train_labels, raw_embedding_glove)\n",
        "test_vec_glove, test_labels_glove_new = all_documents(test_clean_glove, test_labels, raw_embedding_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PERfU7o7E4Rz",
        "outputId": "20869033-ebb2-4d58-f377-0b00f43f350f"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(train_vec_glove, train_labels_glove_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pj-naPkFBzH",
        "outputId": "6351243c-219d-4d1d-9443-c0df80fde40a"
      },
      "source": [
        "y_train_pred = lr.predict(train_vec_glove)\n",
        "print('Training set accuracy %s' % accuracy_score(train_labels_glove_new, y_train_pred))\n",
        "print(classification_report(train_labels_glove_new, y_train_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy 0.8752755457583731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     85925\n",
            "           1       0.84      0.84      0.84     54705\n",
            "\n",
            "    accuracy                           0.88    140630\n",
            "   macro avg       0.87      0.87      0.87    140630\n",
            "weighted avg       0.88      0.88      0.88    140630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX-JhM2MMsTn",
        "outputId": "255acc22-f9df-4032-b23e-ae1468600593"
      },
      "source": [
        "y_test_pred = lr.predict(test_vec_glove)\n",
        "print('Training set accuracy %s' % accuracy_score(test_labels_glove_new, y_test_pred))\n",
        "print(classification_report(test_labels_glove_new, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set accuracy 0.8775597269624573\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     21483\n",
            "           1       0.84      0.85      0.84     13677\n",
            "\n",
            "    accuracy                           0.88     35160\n",
            "   macro avg       0.87      0.87      0.87     35160\n",
            "weighted avg       0.88      0.88      0.88     35160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHI3budNNPg7"
      },
      "source": [
        "glove_test_accuracy_score = accuracy_score(test_labels_glove_new, y_test_pred)\n",
        "glove_test_precision_score = precision_score(test_labels_glove_new, y_test_pred)\n",
        "glove_test_recall_score = recall_score(test_labels_glove_new, y_test_pred)\n",
        "glove_test_f1_score = f1_score(test_labels_glove_new, y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYvDBj1C4Agf"
      },
      "source": [
        "# Summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI4iujVW4ETO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19960989-cc32-4189-9df6-a837441b4971"
      },
      "source": [
        "table = PrettyTable()\n",
        "table.field_names = ['Model - Logistic Regression', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "table.add_row(['Word2Vec', \n",
        "               format(word2vec_test_accuracy_score, '.4f'), \n",
        "               format(word2vec_test_precision_score, '.4f'), \n",
        "               format(word2vec_test_recall_score, '.4f'), \n",
        "               format(word2vec_test_f1_score, '.4f')])\n",
        "\n",
        "table.add_row(['GloVe', \n",
        "               format(glove_test_accuracy_score, '.4f'), \n",
        "               format(glove_test_precision_score, '.4f'), \n",
        "               format(glove_test_recall_score, '.4f'), \n",
        "               format(glove_test_f1_score, '.4f')])\n",
        "print(table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+----------+-----------+--------+----------+\n",
            "| Model - Logistic Regression | Accuracy | Precision | Recall | F1 Score |\n",
            "+-----------------------------+----------+-----------+--------+----------+\n",
            "|           Word2Vec          |  0.9043  |   0.8754  | 0.8792 |  0.8773  |\n",
            "|            GloVe            |  0.8776  |   0.8401  | 0.8463 |  0.8432  |\n",
            "+-----------------------------+----------+-----------+--------+----------+\n"
          ]
        }
      ]
    }
  ]
}